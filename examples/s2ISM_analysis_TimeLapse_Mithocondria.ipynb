{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e91ce4d-3350-4527-aeb0-daead0387ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ggarre\\AppData\\Local\\anaconda3\\envs\\s2ism\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import brighteyes_ism.dataio.mcs as mcs\n",
    "import brighteyes_ism.analysis.Graph_lib as gr\n",
    "import brighteyes_ism.simulation.PSF_sim as sim\n",
    "\n",
    "from s2ism import s2ism as amd\n",
    "import s2ism.psf_estimator as est\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b97213d1-cb94-4588-9162-00f1a4118631",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d1855a-2eb0-4925-b42b-a6cfe29e3028",
   "metadata": {},
   "source": [
    "Importing the raw ISM dataset from the bunch of experimental datasets shown in the paper. \n",
    "The experimental dataset can be downloaded from https://doi.org/10.5281/zenodo.11284051.\r\n",
    "\r\n",
    "Here, we download and decompress the data into the Downldoas folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65322bf-0bff-4040-bee8-7c062321a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm, trange\n",
    "from pathlib import Path\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "def download(url, fname):\n",
    "    resp = requests.get(url, stream=True)\n",
    "    total = int(resp.headers.get('content-length', 0))\n",
    "    with open(fname, 'wb') as file, tqdm(\n",
    "            desc=fname,\n",
    "            total=total,\n",
    "            unit='iB',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for data in resp.iter_content(chunk_size=1024):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "            \n",
    "def extract(filename):\n",
    "    dir_name = filename[:-4]\n",
    "    os.mkdir(dir_name)\n",
    "    with zipfile.ZipFile(filename, 'r') as zf:\n",
    "        for member in tqdm(zf.infolist(), desc='Extracting '):\n",
    "            try:\n",
    "                zf.extract(member, dir_name)\n",
    "            except zipfile.error as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebe02816-9c24-4717-b892-2912ae82682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloads_path = str(Path.home() / 'Downloads')\n",
    "\n",
    "url_data = 'https://zenodo.org/records/11284051/files/h5_files_s2ism.zip'\n",
    "name_data = 'h5_files_s2ism.zip'\n",
    "\n",
    "filename = os.path.join(downloads_path, name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd2db3f-a59f-4a1d-bcb0-d45ce79638ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data:C:\\Users\\ggarre\\Downloads\\h5_files_s2ism.zip\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ggarre\\Downloads\\h5_files_s2ism.zip: 100%|██████████| 3.65G/3.65G [11:57<00:00, 5.47MiB/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(filename):\n",
    "    print('Downloading data:' + filename + '\\n')\n",
    "    download(url_data, filename)\n",
    "else:\n",
    "    print('File already downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75e89732-e5b0-437e-93de-b59e275ca218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting compressed data:\n",
      "\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\ggarre\\\\Downloads\\\\h5_files_s2ism'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(dir_name):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtracting compressed data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m, in \u001b[0;36mextract\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract\u001b[39m(filename):\n\u001b[0;32m     22\u001b[0m     dir_name \u001b[38;5;241m=\u001b[39m filename[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zf:\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m member \u001b[38;5;129;01min\u001b[39;00m tqdm(zf\u001b[38;5;241m.\u001b[39minfolist(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\ggarre\\\\Downloads\\\\h5_files_s2ism'"
     ]
    }
   ],
   "source": [
    "dir_name = filename[:-4]\n",
    "\n",
    "if not os.path.isfile(dir_name):\n",
    "    print('Extracting compressed data:\\n')\n",
    "    extract(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a72d0-60e6-4580-85e8-10349750355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Mithocondria_timelapse_data-09-11-2023-12-47-10.h5'\n",
    "\n",
    "fullpath = os.path.join(dir_name, file)\n",
    "\n",
    "data, meta = mcs.load(fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6cbb1-72f4-41d7-a8e3-f43f0b0d693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0a088f-f9c6-4fdf-970f-7e4e4f87b901",
   "metadata": {},
   "source": [
    "Squeezing the unnecessary dimensions and summing over the temporal bins to obtain a good SNR, nedded to launch the analysis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9982f7d-71c2-49df-bd6c-effff9673858",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = np.squeeze(data)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10816d-4d2d-4ad1-a70a-60028bd6938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = dset.sum(axis = -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f22c7a-a1d3-4cea-bb0b-1f6f44e3d104",
   "metadata": {},
   "source": [
    "Exctracting some dimensions from the raw dataset needed for the upcoming analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0abf7c5-e105-46dc-b944-16162bfcb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = dset.shape\n",
    "N = int( np.sqrt(sz[-1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3505ac-0202-4c19-bc4f-9b5976df3d29",
   "metadata": {},
   "source": [
    "Simulating the complete PSFs extracting some fundamental characteristics of the imaging system from the raw dataset (for a deeper description of this process, check the 'Reconstruction_step_by_step_exp.ipynb' file notebook attached in the GitHub part of the ope-source code). In such a way we maximize the physical reliability of the simulation, obtaining PSFs as close as possible to the experimental ones (effectively describing the custom ISM setup used to acquire this particular dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7895347-7cd8-4ff0-bb91-84307a09acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exPar = sim.simSettings()\n",
    "exPar.wl = 561\n",
    "exPar.mask_sampl = 101\n",
    "\n",
    "emPar = exPar.copy()\n",
    "emPar.wl = 590\n",
    "\n",
    "Nx = meta.nx\n",
    "Ny = meta.ny\n",
    "\n",
    "grid = sim.GridParameters()\n",
    "grid.pxsizex = meta.dx*1e3\n",
    "grid.Nz = 2\n",
    "\n",
    "psf_fin, det_psf, exc_psf = est.psf_estimator_from_data(dset, exPar, emPar, grid, z_out_of_focus='300')   \n",
    "#out-of-focus position for the reconstruction is a-priori posed, and based on quantitative analysis deeply described in the paper itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b2656-6278-4c7d-b042-debc6aa83d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "spad_size = grid.spad_size() / emPar.airy_unit\n",
    "print(f'SPAD array size = {spad_size:.1f} AU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167085e-d389-4e34-b7f9-3701d838ff94",
   "metadata": {},
   "source": [
    "Qualitative check of the simulated PSFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27d6cc-deb8-4f1f-910f-f8502a053527",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ShowDataset(psf_fin[0])\n",
    "gr.ShowDataset(psf_fin[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f01594-e0e8-4c77-9fc7-699c56d27f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_frames = sz[0]\n",
    "\n",
    "ml_frames = np.empty( (time_frames, meta.nx, meta.ny) )\n",
    "\n",
    "for f in trange(time_frames):\n",
    "    s2ism_result = amd.max_likelihood_reconstruction(dset[f], psf_fin, stop = 'fixed', max_iter = 20, rep_to_save ='last')\n",
    "    \n",
    "    obj = amd_result[0]\n",
    "    \n",
    "    ml_frames[f] = obj[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe2110-22fe-4176-89e5-495ec5c77390",
   "metadata": {},
   "source": [
    "Qualitative check of the s2ism in-focus reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9adb93-cb65-41c9-aca8-98e7822c155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ShowStack(ml_frames, meta.dx, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
